Training Dataset Batches: 32
Validation Dataset Batches: 4
Network3(
  (cnn): Sequential(
    (0): Conv2d (2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (downsample): Sequential(
          (0): Conv2d (64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (downsample): Sequential(
          (0): Conv2d (128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (downsample): Sequential(
          (0): Conv2d (256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (8): AvgPool2d(kernel_size=7, stride=1, padding=0, ceil_mode=False, count_include_pad=True)
  )
  (lstm): LSTM(512, 128)
  (linear): Linear(in_features=128, out_features=4)
)
Epoch 1/50
----------
Train Loss: 1.2627 Acc: 0.3600
Valid Loss: 1.2006 Acc: 0.3600
Epoch complete in 6m 37s

Epoch 2/50
----------
Train Loss: 1.2195 Acc: 0.3892
Valid Loss: 1.2054 Acc: 0.3200
Epoch complete in 6m 20s

Epoch 3/50
----------
Train Loss: 1.2161 Acc: 0.3956
Valid Loss: 1.1903 Acc: 0.3657
Epoch complete in 6m 20s

Epoch 4/50
----------
Train Loss: 1.2081 Acc: 0.4076
Valid Loss: 1.1880 Acc: 0.3886
Epoch complete in 6m 20s

Epoch 5/50
----------
Train Loss: 1.2091 Acc: 0.3943
Valid Loss: 1.1896 Acc: 0.3771
Epoch complete in 6m 20s

Epoch 6/50
----------
Train Loss: 1.2021 Acc: 0.4267
Valid Loss: 1.1794 Acc: 0.4286
Epoch complete in 6m 20s

Epoch 7/50
----------
Train Loss: 1.1954 Acc: 0.4362
Valid Loss: 1.1660 Acc: 0.4057
Epoch complete in 6m 20s

Epoch 8/50
----------
Train Loss: 1.1973 Acc: 0.4254
Valid Loss: 1.1815 Acc: 0.4000
Epoch complete in 6m 20s

Epoch 9/50
----------
Train Loss: 1.1861 Acc: 0.4394
Valid Loss: 1.1602 Acc: 0.4457
Epoch complete in 6m 20s

Epoch 10/50
----------
Train Loss: 1.1851 Acc: 0.4521
Valid Loss: 1.1645 Acc: 0.4229
Epoch complete in 6m 21s

Epoch 11/50
----------
Train Loss: 1.1846 Acc: 0.4533
Valid Loss: 1.1581 Acc: 0.4571
Epoch complete in 6m 21s

Epoch 12/50
----------
Train Loss: 1.1767 Acc: 0.4571
Valid Loss: 1.1634 Acc: 0.4171
Epoch complete in 6m 21s

Epoch 13/50
----------
Train Loss: 1.1780 Acc: 0.4540
Valid Loss: 1.1574 Acc: 0.4457
Epoch complete in 6m 22s

Epoch 14/50
----------
Train Loss: 1.1682 Acc: 0.4679
Valid Loss: 1.1829 Acc: 0.4343
Epoch complete in 6m 20s

Epoch 15/50
----------
Train Loss: 1.1758 Acc: 0.4400
Valid Loss: 1.1603 Acc: 0.4400
Epoch complete in 6m 21s

Epoch 16/50
----------
Train Loss: 1.1690 Acc: 0.4692
Valid Loss: 1.2088 Acc: 0.4114
Epoch complete in 6m 20s

Epoch 17/50
----------
Train Loss: 1.1648 Acc: 0.4679
Valid Loss: 1.1820 Acc: 0.4457
Epoch complete in 6m 22s

Epoch 18/50
----------
Train Loss: 1.1528 Acc: 0.4997
Valid Loss: 1.1821 Acc: 0.4457
Epoch complete in 6m 21s

Epoch 19/50
----------
Train Loss: 1.1580 Acc: 0.4711
Valid Loss: 1.1406 Acc: 0.4629
Epoch complete in 6m 22s

Epoch 20/50
----------
Train Loss: 1.1520 Acc: 0.4737
Valid Loss: 1.1552 Acc: 0.4286
Epoch complete in 6m 21s

Epoch 21/50
----------
Train Loss: 1.1517 Acc: 0.4641
Valid Loss: 1.1608 Acc: 0.4343
Epoch complete in 6m 21s

Epoch 22/50
----------
Train Loss: 1.1432 Acc: 0.4756
Valid Loss: 1.1514 Acc: 0.4171
Epoch complete in 6m 22s

Epoch 23/50
----------
Train Loss: 1.1628 Acc: 0.4698
Valid Loss: 1.1489 Acc: 0.4286
Epoch complete in 6m 21s

Epoch 24/50
----------
Train Loss: 1.1474 Acc: 0.4851
Valid Loss: 1.1502 Acc: 0.4400
Epoch complete in 6m 21s

Epoch 25/50
----------
Train Loss: 1.1349 Acc: 0.4914
Valid Loss: 1.1451 Acc: 0.4286
Epoch complete in 6m 22s

Epoch 26/50
----------
Train Loss: 1.1388 Acc: 0.4883
Valid Loss: 1.1541 Acc: 0.4629
Epoch complete in 6m 21s

Epoch 27/50
----------
Train Loss: 1.1393 Acc: 0.4902
Valid Loss: 1.1505 Acc: 0.4457
Epoch complete in 6m 22s

Epoch 28/50
----------
Train Loss: 1.1375 Acc: 0.4775
Valid Loss: 1.1622 Acc: 0.4571
Epoch complete in 6m 22s

Epoch 29/50
----------
Train Loss: 1.1447 Acc: 0.4743
Valid Loss: 1.1710 Acc: 0.3943
Epoch complete in 6m 22s

Epoch 30/50
----------
Train Loss: 1.1258 Acc: 0.5079
Valid Loss: 1.1857 Acc: 0.4286
Epoch complete in 6m 22s

Epoch 31/50
----------
Train Loss: 1.1094 Acc: 0.5067
Valid Loss: 1.1526 Acc: 0.4114
Epoch complete in 6m 21s

Epoch 32/50
----------
Train Loss: 1.1128 Acc: 0.5073
Valid Loss: 1.1484 Acc: 0.4400
Epoch complete in 6m 21s

Epoch 33/50
----------
Train Loss: 1.1266 Acc: 0.4940
Valid Loss: 1.1615 Acc: 0.4800
Epoch complete in 6m 22s

Epoch 34/50
----------
Train Loss: 1.1121 Acc: 0.5086
Valid Loss: 1.1442 Acc: 0.4514
Epoch complete in 6m 22s

Epoch 35/50
----------
Train Loss: 1.0984 Acc: 0.5206
Valid Loss: 1.1420 Acc: 0.4286
Epoch complete in 6m 24s

Epoch 36/50
----------
Train Loss: 1.0982 Acc: 0.5149
Valid Loss: 1.1520 Acc: 0.4686
Epoch complete in 6m 22s

Epoch 37/50
----------
Train Loss: 1.1071 Acc: 0.5098
Valid Loss: 1.1186 Acc: 0.4743
Epoch complete in 6m 21s

Epoch 38/50
----------
Train Loss: 1.1190 Acc: 0.5022
Valid Loss: 1.1274 Acc: 0.4286
Epoch complete in 6m 22s

Epoch 39/50
----------
Train Loss: 1.0931 Acc: 0.5219
Valid Loss: 1.1193 Acc: 0.4629
Epoch complete in 6m 30s

Epoch 40/50
----------
Train Loss: 1.0887 Acc: 0.5283
Valid Loss: 1.1459 Acc: 0.4571
Epoch complete in 6m 22s

Epoch 41/50
----------
Train Loss: 1.1077 Acc: 0.5016
Valid Loss: 1.1953 Acc: 0.4343
Epoch complete in 6m 22s

Epoch 42/50
----------
Train Loss: 1.0899 Acc: 0.5321
Valid Loss: 1.1493 Acc: 0.4229
Epoch complete in 6m 38s

Epoch 43/50
----------
Train Loss: 1.0846 Acc: 0.5137
Valid Loss: 1.1404 Acc: 0.5029
Epoch complete in 6m 26s

Epoch 44/50
----------
Train Loss: 1.0846 Acc: 0.5219
Valid Loss: 1.1209 Acc: 0.4343
Epoch complete in 6m 23s

Epoch 45/50
----------
Train Loss: 1.0707 Acc: 0.5314
Valid Loss: 1.1324 Acc: 0.4457
Epoch complete in 6m 21s

Epoch 46/50
----------
Train Loss: 1.0834 Acc: 0.5187
Valid Loss: 1.1703 Acc: 0.4686
Epoch complete in 6m 21s

Epoch 47/50
----------
Train Loss: 1.0696 Acc: 0.5232
Valid Loss: 1.1630 Acc: 0.4400
Epoch complete in 6m 22s

Epoch 48/50
----------
Train Loss: 1.0797 Acc: 0.5200
Valid Loss: 1.1522 Acc: 0.4514
Epoch complete in 6m 21s

Epoch 49/50
----------
Train Loss: 1.0598 Acc: 0.5448
Valid Loss: 1.1144 Acc: 0.4514
Epoch complete in 6m 21s

Epoch 50/50
----------
Train Loss: 1.0628 Acc: 0.5416
Valid Loss: 1.1372 Acc: 0.4800
Epoch complete in 6m 21s

Best Validation Accuracy: 0.5028571428571429
