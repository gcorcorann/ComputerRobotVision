Training Dataset Batches: 32
Validation Dataset Batches: 4
Network3(
  (cnn): Sequential(
    (0): Conv2d (2, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
    (2): ReLU(inplace)
    (3): MaxPool2d(kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), dilation=(1, 1))
    (4): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      )
      (1): BasicBlock(
        (conv1): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (5): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (downsample): Sequential(
          (0): Conv2d (64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (6): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (downsample): Sequential(
          (0): Conv2d (128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (7): Sequential(
      (0): BasicBlock(
        (conv1): Conv2d (256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (downsample): Sequential(
          (0): Conv2d (256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        )
      )
      (1): BasicBlock(
        (conv1): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
        (relu): ReLU(inplace)
        (conv2): Conv2d (512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True)
      )
    )
    (8): AvgPool2d(kernel_size=7, stride=1, padding=0, ceil_mode=False, count_include_pad=True)
  )
  (lstm): LSTM(512, 128)
  (linear): Linear(in_features=128, out_features=4)
)
Epoch 1/50
----------
Train Loss: 1.3496 Acc: 0.3543
Valid Loss: 1.3075 Acc: 0.3600
Epoch complete in 6m 21s

Epoch 2/50
----------
Train Loss: 1.2929 Acc: 0.3549
Valid Loss: 1.2600 Acc: 0.3657
Epoch complete in 6m 20s

Epoch 3/50
----------
Train Loss: 1.2608 Acc: 0.3581
Valid Loss: 1.2297 Acc: 0.3543
Epoch complete in 6m 20s

Epoch 4/50
----------
Train Loss: 1.2427 Acc: 0.3784
Valid Loss: 1.2160 Acc: 0.3829
Epoch complete in 6m 22s

Epoch 5/50
----------
Train Loss: 1.2330 Acc: 0.3892
Valid Loss: 1.2053 Acc: 0.3657
Epoch complete in 6m 21s

Epoch 6/50
----------
Train Loss: 1.2272 Acc: 0.3803
Valid Loss: 1.2000 Acc: 0.3714
Epoch complete in 6m 20s

Epoch 7/50
----------
Train Loss: 1.2237 Acc: 0.3943
Valid Loss: 1.1966 Acc: 0.3829
Epoch complete in 6m 31s

Epoch 8/50
----------
Train Loss: 1.2223 Acc: 0.3924
Valid Loss: 1.1936 Acc: 0.4000
Epoch complete in 6m 30s

Epoch 9/50
----------
Train Loss: 1.2199 Acc: 0.3873
Valid Loss: 1.1907 Acc: 0.4171
Epoch complete in 6m 31s

Epoch 10/50
----------
Train Loss: 1.2179 Acc: 0.3930
Valid Loss: 1.1876 Acc: 0.4571
Epoch complete in 6m 31s

Epoch 11/50
----------
Train Loss: 1.2171 Acc: 0.4019
Valid Loss: 1.1870 Acc: 0.4286
Epoch complete in 6m 31s

Epoch 12/50
----------
Train Loss: 1.2165 Acc: 0.4083
Valid Loss: 1.1854 Acc: 0.4057
Epoch complete in 6m 30s

Epoch 13/50
----------
Train Loss: 1.2154 Acc: 0.3867
Valid Loss: 1.1830 Acc: 0.4400
Epoch complete in 6m 31s

Epoch 14/50
----------
Train Loss: 1.2143 Acc: 0.3937
Valid Loss: 1.1800 Acc: 0.4514
Epoch complete in 6m 31s

Epoch 15/50
----------
Train Loss: 1.2122 Acc: 0.3975
Valid Loss: 1.1819 Acc: 0.4743
Epoch complete in 6m 30s

Epoch 16/50
----------
Train Loss: 1.2119 Acc: 0.4083
Valid Loss: 1.1801 Acc: 0.4571
Epoch complete in 6m 30s

Epoch 17/50
----------
Train Loss: 1.2120 Acc: 0.3956
Valid Loss: 1.1758 Acc: 0.4343
Epoch complete in 6m 30s

Epoch 18/50
----------
Train Loss: 1.2099 Acc: 0.4070
Valid Loss: 1.1776 Acc: 0.4343
Epoch complete in 6m 31s

Epoch 19/50
----------
Train Loss: 1.2084 Acc: 0.4114
Valid Loss: 1.1759 Acc: 0.4457
Epoch complete in 6m 31s

Epoch 20/50
----------
Train Loss: 1.2077 Acc: 0.4095
Valid Loss: 1.1729 Acc: 0.4571
Epoch complete in 6m 30s

Epoch 21/50
----------
Train Loss: 1.2068 Acc: 0.4184
Valid Loss: 1.1740 Acc: 0.4457
Epoch complete in 6m 30s

Epoch 22/50
----------
Train Loss: 1.2063 Acc: 0.4216
Valid Loss: 1.1715 Acc: 0.4571
Epoch complete in 6m 30s

Epoch 23/50
----------
Train Loss: 1.2045 Acc: 0.4121
Valid Loss: 1.1696 Acc: 0.4743
Epoch complete in 6m 31s

Epoch 24/50
----------
Train Loss: 1.2040 Acc: 0.4152
Valid Loss: 1.1676 Acc: 0.4514
Epoch complete in 6m 32s

Epoch 25/50
----------
Train Loss: 1.2019 Acc: 0.4210
Valid Loss: 1.1686 Acc: 0.4629
Epoch complete in 6m 28s

Epoch 26/50
----------
Train Loss: 1.2028 Acc: 0.4133
Valid Loss: 1.1639 Acc: 0.5029
Epoch complete in 6m 20s

Epoch 27/50
----------
Train Loss: 1.2002 Acc: 0.4203
Valid Loss: 1.1630 Acc: 0.4629
Epoch complete in 6m 20s

Epoch 28/50
----------
Train Loss: 1.1988 Acc: 0.4305
Valid Loss: 1.1621 Acc: 0.4743
Epoch complete in 6m 20s

Epoch 29/50
----------
Train Loss: 1.1970 Acc: 0.4241
Valid Loss: 1.1666 Acc: 0.4743
Epoch complete in 6m 20s

Epoch 30/50
----------
Train Loss: 1.1968 Acc: 0.4241
Valid Loss: 1.1633 Acc: 0.4857
Epoch complete in 6m 20s

Epoch 31/50
----------
Train Loss: 1.1943 Acc: 0.4317
Valid Loss: 1.1646 Acc: 0.4686
Epoch complete in 6m 20s

Epoch 32/50
----------
Train Loss: 1.1949 Acc: 0.4190
Valid Loss: 1.1617 Acc: 0.4571
Epoch complete in 6m 20s

Epoch 33/50
----------
Train Loss: 1.1950 Acc: 0.4273
Valid Loss: 1.1584 Acc: 0.4914
Epoch complete in 6m 20s

Epoch 34/50
----------
Train Loss: 1.1924 Acc: 0.4229
Valid Loss: 1.1583 Acc: 0.4914
Epoch complete in 6m 20s

Epoch 35/50
----------
Train Loss: 1.1936 Acc: 0.4241
Valid Loss: 1.1612 Acc: 0.4571
Epoch complete in 6m 19s

Epoch 36/50
----------
Train Loss: 1.1910 Acc: 0.4279
Valid Loss: 1.1560 Acc: 0.4743
Epoch complete in 6m 20s

Epoch 37/50
----------
Train Loss: 1.1904 Acc: 0.4387
Valid Loss: 1.1561 Acc: 0.4857
Epoch complete in 6m 20s

Epoch 38/50
----------
Train Loss: 1.1875 Acc: 0.4387
Valid Loss: 1.1621 Acc: 0.4571
Epoch complete in 6m 21s

Epoch 39/50
----------
Train Loss: 1.1862 Acc: 0.4387
Valid Loss: 1.1546 Acc: 0.4743
Epoch complete in 6m 24s

Epoch 40/50
----------
Train Loss: 1.1865 Acc: 0.4337
Valid Loss: 1.1558 Acc: 0.4571
Epoch complete in 6m 19s

Epoch 41/50
----------
Train Loss: 1.1856 Acc: 0.4451
Valid Loss: 1.1529 Acc: 0.4971
Epoch complete in 6m 20s

Epoch 42/50
----------
Train Loss: 1.1845 Acc: 0.4419
Valid Loss: 1.1542 Acc: 0.4686
Epoch complete in 6m 21s

Epoch 43/50
----------
Train Loss: 1.1834 Acc: 0.4387
Valid Loss: 1.1553 Acc: 0.4857
Epoch complete in 6m 20s

Epoch 44/50
----------
Train Loss: 1.1819 Acc: 0.4387
Valid Loss: 1.1513 Acc: 0.4514
Epoch complete in 6m 28s

Epoch 45/50
----------
Train Loss: 1.1827 Acc: 0.4273
Valid Loss: 1.1520 Acc: 0.4743
Epoch complete in 6m 30s

Epoch 46/50
----------
Train Loss: 1.1790 Acc: 0.4463
Valid Loss: 1.1507 Acc: 0.4857
Epoch complete in 6m 29s

Epoch 47/50
----------
Train Loss: 1.1783 Acc: 0.4375
Valid Loss: 1.1547 Acc: 0.4743
Epoch complete in 6m 30s

Epoch 48/50
----------
Train Loss: 1.1791 Acc: 0.4394
Valid Loss: 1.1493 Acc: 0.4800
Epoch complete in 6m 31s

Epoch 49/50
----------
Train Loss: 1.1786 Acc: 0.4394
Valid Loss: 1.1487 Acc: 0.4857
Epoch complete in 6m 31s

Epoch 50/50
----------
Train Loss: 1.1765 Acc: 0.4330
Valid Loss: 1.1552 Acc: 0.4800
Epoch complete in 6m 31s

Best Validation Accuracy: 0.5028571428571429
